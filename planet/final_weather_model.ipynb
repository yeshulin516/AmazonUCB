{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from six import string_types\n",
    "\n",
    "# Make sure you have all of these packages installed, e.g. via pip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy\n",
    "from skimage import io\n",
    "from scipy import ndimage\n",
    "from IPython.display import display\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PLANET_KAGGLE_ROOT = os.path.abspath(\"/Users/sunchenxi/Desktop/lab/kaggle/amazon/\")\n",
    "PLANET_KAGGLE_JPEG_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'train-jpg')\n",
    "PLANET_KAGGLE_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_v2.csv')\n",
    "assert os.path.exists(PLANET_KAGGLE_ROOT)\n",
    "assert os.path.exists(PLANET_KAGGLE_JPEG_DIR)\n",
    "assert os.path.exists(PLANET_KAGGLE_LABEL_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>haze</th>\n",
       "      <th>primary</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>clear</th>\n",
       "      <th>water</th>\n",
       "      <th>habitation</th>\n",
       "      <th>road</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>blooming</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>blow_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags  haze  primary  \\\n",
       "0    train_0                               haze primary     1        1   \n",
       "1    train_1            agriculture clear primary water     0        1   \n",
       "2    train_2                              clear primary     0        1   \n",
       "3    train_3                              clear primary     0        1   \n",
       "4    train_4  agriculture clear habitation primary road     0        1   \n",
       "\n",
       "   agriculture  clear  water  habitation  road  cultivation  slash_burn  \\\n",
       "0            0      0      0           0     0            0           0   \n",
       "1            1      1      1           0     0            0           0   \n",
       "2            0      1      0           0     0            0           0   \n",
       "3            0      1      0           0     0            0           0   \n",
       "4            1      1      0           1     1            0           0   \n",
       "\n",
       "   cloudy  partly_cloudy  conventional_mine  bare_ground  artisinal_mine  \\\n",
       "0       0              0                  0            0               0   \n",
       "1       0              0                  0            0               0   \n",
       "2       0              0                  0            0               0   \n",
       "3       0              0                  0            0               0   \n",
       "4       0              0                  0            0               0   \n",
       "\n",
       "   blooming  selective_logging  blow_down  \n",
       "0         0                  0          0  \n",
       "1         0                  0          0  \n",
       "2         0                  0          0  \n",
       "3         0                  0          0  \n",
       "4         0                  0          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_images(tags, n=None):\n",
    "    \"\"\"Randomly sample n images with the specified tags.\"\"\"\n",
    "    condition = True\n",
    "    if isinstance(tags, string_types): #tag是否是string类型\n",
    "        raise ValueError(\"Pass a list of tags, not a single tag.\")\n",
    "    for tag in tags:\n",
    "        condition = condition & labels_df[tag] == 1\n",
    "    if n is not None:\n",
    "        return labels_df[condition].sample(n)\n",
    "    else:\n",
    "        return labels_df[condition]\n",
    "def load_image(filename):\n",
    "    '''Look through the directory tree to find the image you specified\n",
    "    (e.g. train_10.tif vs. train_10.jpg)'''\n",
    "    for dirname in os.listdir(PLANET_KAGGLE_ROOT):\n",
    "        path = os.path.abspath(os.path.join(PLANET_KAGGLE_ROOT, dirname, filename))\n",
    "        if os.path.exists(path):\n",
    "            print('Found image {}'.format(path))\n",
    "            return io.imread(path)\n",
    "    print('Load failed: could not find image {}'.format(path))\n",
    "def sample_to_fname(sample_df, row_idx, suffix='jpg'):\n",
    "    '''Given a dataframe of sampled images, get the\n",
    "    corresponding filename.'''\n",
    "    fname = sample_df.get_value(sample_df.index[row_idx], 'image_name')\n",
    "    return '{}.{}'.format(fname, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "for i in range(len(labels_df)):\n",
    "    if(labels_df[\"clear\"][i]==1):\n",
    "        n=n+1\n",
    "fname=[0]*n\n",
    "s = sample_images(['clear'], n=n)\n",
    "for i in range(n):\n",
    "    fname[i]= sample_to_fname(s, i)\n",
    "n1=0\n",
    "for i in range(len(labels_df)):\n",
    "    if(labels_df[\"partly_cloudy\"][i]==1):\n",
    "        n1=n1+1\n",
    "fname1=[0]*n1\n",
    "s = sample_images(['partly_cloudy'], n=n1)\n",
    "for i in range(n1):\n",
    "    fname1[i]= sample_to_fname(s, i)\n",
    "n2=0\n",
    "for i in range(len(labels_df)):\n",
    "    if(labels_df[\"haze\"][i]==1):\n",
    "        n2=n2+1\n",
    "fname2=[0]*n1\n",
    "s = sample_images(['haze'], n=n2)\n",
    "for i in range(n2):\n",
    "    fname2[i]= sample_to_fname(s, i)\n",
    "n3=0\n",
    "for i in range(len(labels_df)):\n",
    "    if(labels_df[\"cloudy\"][i]==1):\n",
    "        n3=n3+1\n",
    "fname3=[0]*n1\n",
    "s = sample_images(['cloudy'], n=n3)\n",
    "for i in range(n3):\n",
    "    fname3[i]= sample_to_fname(s, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clear_img = [cv2.imread(PLANET_KAGGLE_ROOT+'/train-jpg/'+ img) for img in fname[:1000]]\n",
    "partly_cloudy_img=[cv2.imread(PLANET_KAGGLE_ROOT+'/train-jpg/'+ img) for img in fname1[:1000]]\n",
    "haze_cloudy_img=[cv2.imread(PLANET_KAGGLE_ROOT+'/train-jpg/'+ img) for img in fname2[:1000]]\n",
    "cloudy_img=[cv2.imread(PLANET_KAGGLE_ROOT+'/train-jpg/'+ img) for img in fname3[:1000]]\n",
    "weather_img=clear_img+partly_cloudy_img+haze_cloudy_img+cloudy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resized_images = [np.reshape(cv2.resize(img,(64,64),interpolation=cv2.INTER_AREA), [1,64,64,3]) for img in weather_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_labels=[1,0,0,0]*1000\n",
    "partly_labels=[0,1,0,0]*1000\n",
    "haze_labels=[0,0,1,0]*1000\n",
    "cloudy_labels=[0,0,0,1]*1000\n",
    "weater_labels=clear_labels+partly_labels+haze_labels+cloudy_labels\n",
    "weater_labels=np.asarray(weater_labels).reshape(4000,4)\n",
    "weater_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x=np.vstack((resized_images))\n",
    "train_y=weater_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 65,  71,  57],\n",
       "         [ 63,  69,  53],\n",
       "         [ 62,  72,  61],\n",
       "         ..., \n",
       "         [ 60,  64,  50],\n",
       "         [ 61,  67,  53],\n",
       "         [ 57,  62,  48]],\n",
       "\n",
       "        [[ 60,  67,  53],\n",
       "         [ 60,  68,  53],\n",
       "         [ 64,  69,  56],\n",
       "         ..., \n",
       "         [ 60,  66,  50],\n",
       "         [ 63,  68,  54],\n",
       "         [ 59,  64,  49]],\n",
       "\n",
       "        [[ 65,  70,  54],\n",
       "         [ 59,  63,  49],\n",
       "         [ 62,  69,  53],\n",
       "         ..., \n",
       "         [ 60,  65,  50],\n",
       "         [ 62,  68,  53],\n",
       "         [ 59,  64,  49]],\n",
       "\n",
       "        ..., \n",
       "        [[ 67,  68,  56],\n",
       "         [ 64,  67,  56],\n",
       "         [ 63,  67,  55],\n",
       "         ..., \n",
       "         [ 65,  70,  56],\n",
       "         [ 63,  64,  50],\n",
       "         [ 70,  74,  60]],\n",
       "\n",
       "        [[ 64,  68,  55],\n",
       "         [ 64,  69,  58],\n",
       "         [ 63,  63,  51],\n",
       "         ..., \n",
       "         [ 66,  68,  56],\n",
       "         [ 63,  65,  53],\n",
       "         [ 64,  69,  53]],\n",
       "\n",
       "        [[ 64,  64,  53],\n",
       "         [ 67,  67,  54],\n",
       "         [ 63,  63,  53],\n",
       "         ..., \n",
       "         [ 63,  64,  52],\n",
       "         [ 66,  64,  50],\n",
       "         [ 67,  70,  55]]],\n",
       "\n",
       "\n",
       "       [[[ 31,  39,  34],\n",
       "         [ 32,  42,  38],\n",
       "         [ 35,  46,  40],\n",
       "         ..., \n",
       "         [ 36,  43,  36],\n",
       "         [ 35,  43,  34],\n",
       "         [ 38,  50,  40]],\n",
       "\n",
       "        [[ 31,  41,  31],\n",
       "         [ 34,  43,  37],\n",
       "         [ 36,  46,  37],\n",
       "         ..., \n",
       "         [ 35,  36,  26],\n",
       "         [ 44,  51,  43],\n",
       "         [ 40,  53,  47]],\n",
       "\n",
       "        [[ 32,  42,  31],\n",
       "         [ 36,  40,  33],\n",
       "         [ 38,  44,  37],\n",
       "         ..., \n",
       "         [ 31,  32,  23],\n",
       "         [ 38,  45,  37],\n",
       "         [ 43,  54,  46]],\n",
       "\n",
       "        ..., \n",
       "        [[ 33,  45,  36],\n",
       "         [ 32,  37,  30],\n",
       "         [ 35,  38,  34],\n",
       "         ..., \n",
       "         [ 39,  54,  45],\n",
       "         [ 41,  56,  48],\n",
       "         [ 46,  61,  62]],\n",
       "\n",
       "        [[ 35,  47,  35],\n",
       "         [ 38,  43,  36],\n",
       "         [ 32,  40,  31],\n",
       "         ..., \n",
       "         [ 38,  53,  45],\n",
       "         [ 37,  50,  37],\n",
       "         [ 38,  50,  43]],\n",
       "\n",
       "        [[ 34,  42,  36],\n",
       "         [ 34,  44,  37],\n",
       "         [ 32,  44,  36],\n",
       "         ..., \n",
       "         [ 36,  45,  38],\n",
       "         [ 34,  44,  32],\n",
       "         [ 35,  44,  35]]],\n",
       "\n",
       "\n",
       "       [[[ 88, 105, 130],\n",
       "         [ 80,  99, 118],\n",
       "         [ 74,  88, 103],\n",
       "         ..., \n",
       "         [ 72,  84,  98],\n",
       "         [ 70,  82,  95],\n",
       "         [ 68,  82,  91]],\n",
       "\n",
       "        [[ 90, 107, 132],\n",
       "         [ 86, 105, 127],\n",
       "         [ 79,  94, 114],\n",
       "         ..., \n",
       "         [ 73,  87, 100],\n",
       "         [ 70,  85,  97],\n",
       "         [ 68,  82,  93]],\n",
       "\n",
       "        [[ 90, 109, 133],\n",
       "         [ 88, 107, 131],\n",
       "         [ 86, 104, 124],\n",
       "         ..., \n",
       "         [ 73,  88, 102],\n",
       "         [ 70,  85,  96],\n",
       "         [ 67,  82,  93]],\n",
       "\n",
       "        ..., \n",
       "        [[ 56,  59,  56],\n",
       "         [ 56,  58,  57],\n",
       "         [ 54,  62,  59],\n",
       "         ..., \n",
       "         [ 83,  99, 124],\n",
       "         [ 83,  99, 126],\n",
       "         [ 83, 100, 126]],\n",
       "\n",
       "        [[ 55,  60,  56],\n",
       "         [ 55,  58,  56],\n",
       "         [ 55,  62,  58],\n",
       "         ..., \n",
       "         [ 83, 100, 127],\n",
       "         [ 82,  98, 125],\n",
       "         [ 82,  98, 125]],\n",
       "\n",
       "        [[ 56,  60,  56],\n",
       "         [ 54,  61,  59],\n",
       "         [ 56,  64,  60],\n",
       "         ..., \n",
       "         [ 83, 100, 127],\n",
       "         [ 84,  99, 128],\n",
       "         [ 80,  97, 125]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[159, 160, 149],\n",
       "         [159, 160, 147],\n",
       "         [159, 159, 148],\n",
       "         ..., \n",
       "         [158, 158, 146],\n",
       "         [157, 158, 144],\n",
       "         [159, 158, 144]],\n",
       "\n",
       "        [[159, 160, 148],\n",
       "         [159, 160, 148],\n",
       "         [157, 159, 146],\n",
       "         ..., \n",
       "         [156, 158, 144],\n",
       "         [155, 158, 144],\n",
       "         [157, 158, 144]],\n",
       "\n",
       "        [[160, 159, 147],\n",
       "         [160, 159, 147],\n",
       "         [158, 158, 146],\n",
       "         ..., \n",
       "         [156, 156, 144],\n",
       "         [157, 157, 144],\n",
       "         [157, 157, 145]],\n",
       "\n",
       "        ..., \n",
       "        [[172, 170, 159],\n",
       "         [172, 170, 160],\n",
       "         [173, 170, 160],\n",
       "         ..., \n",
       "         [174, 169, 159],\n",
       "         [173, 171, 158],\n",
       "         [173, 172, 161]],\n",
       "\n",
       "        [[172, 171, 161],\n",
       "         [172, 171, 161],\n",
       "         [173, 171, 160],\n",
       "         ..., \n",
       "         [172, 169, 160],\n",
       "         [172, 171, 159],\n",
       "         [172, 170, 159]],\n",
       "\n",
       "        [[172, 171, 159],\n",
       "         [172, 171, 159],\n",
       "         [173, 171, 160],\n",
       "         ..., \n",
       "         [174, 171, 160],\n",
       "         [172, 171, 159],\n",
       "         [172, 170, 159]]],\n",
       "\n",
       "\n",
       "       [[[148, 160, 154],\n",
       "         [148, 159, 154],\n",
       "         [148, 161, 155],\n",
       "         ..., \n",
       "         [143, 158, 151],\n",
       "         [146, 160, 155],\n",
       "         [144, 158, 152]],\n",
       "\n",
       "        [[148, 159, 154],\n",
       "         [148, 160, 154],\n",
       "         [150, 162, 157],\n",
       "         ..., \n",
       "         [145, 160, 154],\n",
       "         [148, 160, 154],\n",
       "         [146, 158, 151]],\n",
       "\n",
       "        [[147, 161, 154],\n",
       "         [149, 161, 156],\n",
       "         [147, 160, 154],\n",
       "         ..., \n",
       "         [147, 160, 154],\n",
       "         [146, 160, 152],\n",
       "         [144, 156, 150]],\n",
       "\n",
       "        ..., \n",
       "        [[142, 155, 148],\n",
       "         [142, 155, 148],\n",
       "         [143, 156, 149],\n",
       "         ..., \n",
       "         [144, 156, 148],\n",
       "         [138, 150, 144],\n",
       "         [139, 152, 142]],\n",
       "\n",
       "        [[142, 154, 147],\n",
       "         [142, 156, 149],\n",
       "         [143, 156, 150],\n",
       "         ..., \n",
       "         [142, 156, 147],\n",
       "         [140, 152, 144],\n",
       "         [140, 152, 144]],\n",
       "\n",
       "        [[142, 154, 147],\n",
       "         [142, 156, 149],\n",
       "         [143, 158, 150],\n",
       "         ..., \n",
       "         [142, 154, 147],\n",
       "         [140, 152, 144],\n",
       "         [140, 152, 144]]],\n",
       "\n",
       "\n",
       "       [[[189, 191, 191],\n",
       "         [187, 191, 189],\n",
       "         [187, 190, 190],\n",
       "         ..., \n",
       "         [186, 189, 186],\n",
       "         [187, 190, 186],\n",
       "         [187, 190, 186]],\n",
       "\n",
       "        [[189, 193, 191],\n",
       "         [187, 193, 189],\n",
       "         [187, 190, 190],\n",
       "         ..., \n",
       "         [186, 189, 186],\n",
       "         [187, 190, 186],\n",
       "         [187, 190, 186]],\n",
       "\n",
       "        [[188, 191, 190],\n",
       "         [187, 191, 190],\n",
       "         [189, 192, 190],\n",
       "         ..., \n",
       "         [186, 189, 185],\n",
       "         [188, 190, 186],\n",
       "         [186, 190, 186]],\n",
       "\n",
       "        ..., \n",
       "        [[191, 193, 191],\n",
       "         [193, 195, 193],\n",
       "         [193, 194, 192],\n",
       "         ..., \n",
       "         [185, 184, 177],\n",
       "         [187, 186, 179],\n",
       "         [187, 186, 179]],\n",
       "\n",
       "        [[192, 193, 192],\n",
       "         [192, 195, 192],\n",
       "         [193, 194, 192],\n",
       "         ..., \n",
       "         [184, 183, 178],\n",
       "         [186, 185, 178],\n",
       "         [184, 183, 177]],\n",
       "\n",
       "        [[192, 193, 192],\n",
       "         [192, 195, 192],\n",
       "         [193, 194, 192],\n",
       "         ..., \n",
       "         [184, 183, 177],\n",
       "         [186, 185, 177],\n",
       "         [184, 183, 176]]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-5)\n",
    "objective = 'binary_crossentropy'\n",
    "def convnet():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, kernel_size=(3, 3), padding='same', input_shape=(64, 64, 3), activation='relu'))\n",
    "    model.add(Convolution2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(4))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = convnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 1000 samples\n",
      "Epoch 1/1024\n",
      "3000/3000 [==============================] - 175s - loss: 4.0330 - acc: 0.8892 - val_loss: 6.2603 - val_acc: 0.5135\n",
      "Epoch 2/1024\n",
      "3000/3000 [==============================] - 172s - loss: 3.9607 - acc: 0.8894 - val_loss: 5.5074 - val_acc: 0.5232\n",
      "Epoch 3/1024\n",
      "3000/3000 [==============================] - 170s - loss: 3.8913 - acc: 0.8887 - val_loss: 5.9171 - val_acc: 0.5208\n",
      "Epoch 4/1024\n",
      "3000/3000 [==============================] - 163s - loss: 3.8240 - acc: 0.8879 - val_loss: 6.1026 - val_acc: 0.5170\n",
      "Epoch 5/1024\n",
      "3000/3000 [==============================] - 172s - loss: 3.7623 - acc: 0.8898 - val_loss: 6.1435 - val_acc: 0.5092\n",
      "Epoch 6/1024\n",
      "3000/3000 [==============================] - 164s - loss: 3.6987 - acc: 0.8871 - val_loss: 5.1594 - val_acc: 0.5282\n",
      "Epoch 7/1024\n",
      "3000/3000 [==============================] - 170s - loss: 3.6388 - acc: 0.8886 - val_loss: 5.3998 - val_acc: 0.5228\n",
      "Epoch 8/1024\n",
      "3000/3000 [==============================] - 164s - loss: 3.5710 - acc: 0.8911 - val_loss: 5.6912 - val_acc: 0.5170\n",
      "Epoch 9/1024\n",
      "3000/3000 [==============================] - 170s - loss: 3.5117 - acc: 0.8921 - val_loss: 5.3787 - val_acc: 0.5243\n",
      "Epoch 10/1024\n",
      "3000/3000 [==============================] - 171s - loss: 3.4570 - acc: 0.8934 - val_loss: 5.4309 - val_acc: 0.5237\n",
      "Epoch 11/1024\n",
      "3000/3000 [==============================] - 176s - loss: 3.3998 - acc: 0.8908 - val_loss: 6.3535 - val_acc: 0.5075\n",
      "Epoch 12/1024\n",
      "3000/3000 [==============================] - 173s - loss: 3.3466 - acc: 0.8931 - val_loss: 5.8071 - val_acc: 0.5160\n",
      "Epoch 13/1024\n",
      "3000/3000 [==============================] - 183s - loss: 3.2960 - acc: 0.8935 - val_loss: 5.0456 - val_acc: 0.5247\n",
      "Epoch 14/1024\n",
      "3000/3000 [==============================] - 172s - loss: 3.2397 - acc: 0.8998 - val_loss: 5.4120 - val_acc: 0.5215\n",
      "Epoch 15/1024\n",
      "3000/3000 [==============================] - 246s - loss: 3.1942 - acc: 0.8940 - val_loss: 5.5381 - val_acc: 0.5152\n",
      "Epoch 16/1024\n",
      "3000/3000 [==============================] - 305s - loss: 3.1470 - acc: 0.8974 - val_loss: 5.3812 - val_acc: 0.5172\n",
      "Epoch 17/1024\n",
      "3000/3000 [==============================] - 319s - loss: 3.1007 - acc: 0.8949 - val_loss: 5.5081 - val_acc: 0.5150\n",
      "Epoch 18/1024\n",
      "3000/3000 [==============================] - 295s - loss: 3.0622 - acc: 0.8963 - val_loss: 5.6318 - val_acc: 0.5125\n",
      "Epoch 19/1024\n",
      "3000/3000 [==============================] - 245s - loss: 3.0092 - acc: 0.8998 - val_loss: 6.0051 - val_acc: 0.5075\n",
      "Epoch 20/1024\n",
      "3000/3000 [==============================] - 171s - loss: 2.9727 - acc: 0.8974 - val_loss: 5.6546 - val_acc: 0.5117\n",
      "Epoch 21/1024\n",
      "3000/3000 [==============================] - 183s - loss: 2.9299 - acc: 0.8987 - val_loss: 4.9922 - val_acc: 0.5232\n",
      "Epoch 22/1024\n",
      "3000/3000 [==============================] - 183s - loss: 2.8915 - acc: 0.8986 - val_loss: 5.2014 - val_acc: 0.5195\n",
      "Epoch 23/1024\n",
      "3000/3000 [==============================] - 170s - loss: 2.8506 - acc: 0.8997 - val_loss: 5.3241 - val_acc: 0.5153\n",
      "Epoch 24/1024\n",
      "3000/3000 [==============================] - 188s - loss: 2.8102 - acc: 0.9048 - val_loss: 5.4817 - val_acc: 0.5118\n",
      "Epoch 25/1024\n",
      "3000/3000 [==============================] - 174s - loss: 2.7803 - acc: 0.8997 - val_loss: 5.5184 - val_acc: 0.5125\n",
      "Epoch 26/1024\n",
      "3000/3000 [==============================] - 154s - loss: 2.7429 - acc: 0.9029 - val_loss: 5.3611 - val_acc: 0.5205\n",
      "Epoch 27/1024\n",
      "3000/3000 [==============================] - 161s - loss: 2.7087 - acc: 0.9027 - val_loss: 5.3449 - val_acc: 0.5138\n",
      "Epoch 28/1024\n",
      "3000/3000 [==============================] - 166s - loss: 2.6719 - acc: 0.9016 - val_loss: 5.4693 - val_acc: 0.5160\n",
      "Epoch 29/1024\n",
      "3000/3000 [==============================] - 156s - loss: 2.6478 - acc: 0.9002 - val_loss: 4.7712 - val_acc: 0.5242\n",
      "Epoch 30/1024\n",
      "3000/3000 [==============================] - 145s - loss: 2.6062 - acc: 0.9048 - val_loss: 5.2585 - val_acc: 0.5130\n",
      "Epoch 31/1024\n",
      "3000/3000 [==============================] - 166s - loss: 2.5766 - acc: 0.9034 - val_loss: 5.3994 - val_acc: 0.5188\n",
      "Epoch 32/1024\n",
      "3000/3000 [==============================] - 156s - loss: 2.5492 - acc: 0.9039 - val_loss: 5.2080 - val_acc: 0.5195\n",
      "Epoch 33/1024\n",
      "3000/3000 [==============================] - 161s - loss: 2.5193 - acc: 0.9048 - val_loss: 5.3993 - val_acc: 0.5137\n",
      "Epoch 34/1024\n",
      "3000/3000 [==============================] - 181s - loss: 2.4919 - acc: 0.9043 - val_loss: 5.1440 - val_acc: 0.5167\n",
      "Epoch 35/1024\n",
      "3000/3000 [==============================] - 160s - loss: 2.4686 - acc: 0.9049 - val_loss: 5.4678 - val_acc: 0.5118\n",
      "Epoch 36/1024\n",
      "3000/3000 [==============================] - 169s - loss: 2.4385 - acc: 0.9050 - val_loss: 4.8469 - val_acc: 0.5202\n",
      "Epoch 37/1024\n",
      "3000/3000 [==============================] - 156s - loss: 2.4160 - acc: 0.9042 - val_loss: 4.7889 - val_acc: 0.5248\n",
      "Epoch 38/1024\n",
      "3000/3000 [==============================] - 154s - loss: 2.3906 - acc: 0.9050 - val_loss: 5.0386 - val_acc: 0.5185\n",
      "Epoch 39/1024\n",
      "3000/3000 [==============================] - 152s - loss: 2.3632 - acc: 0.9072 - val_loss: 4.8131 - val_acc: 0.5215\n",
      "Epoch 40/1024\n",
      "3000/3000 [==============================] - 172s - loss: 2.3383 - acc: 0.9047 - val_loss: 5.0696 - val_acc: 0.5148\n",
      "Epoch 41/1024\n",
      "3000/3000 [==============================] - 174s - loss: 2.3115 - acc: 0.9094 - val_loss: 5.1574 - val_acc: 0.5173\n",
      "Epoch 42/1024\n",
      "3000/3000 [==============================] - 160s - loss: 2.2897 - acc: 0.9072 - val_loss: 5.0631 - val_acc: 0.5217\n",
      "Epoch 43/1024\n",
      "3000/3000 [==============================] - 157s - loss: 2.2613 - acc: 0.9086 - val_loss: 5.2595 - val_acc: 0.5122\n",
      "Epoch 44/1024\n",
      "3000/3000 [==============================] - 162s - loss: 2.2459 - acc: 0.9078 - val_loss: 5.5580 - val_acc: 0.5102\n",
      "Epoch 45/1024\n",
      "3000/3000 [==============================] - 167s - loss: 2.2217 - acc: 0.9082 - val_loss: 5.5597 - val_acc: 0.5093\n",
      "Epoch 46/1024\n",
      "3000/3000 [==============================] - 165s - loss: 2.1975 - acc: 0.9090 - val_loss: 5.3660 - val_acc: 0.5115\n",
      "Epoch 47/1024\n",
      "3000/3000 [==============================] - 164s - loss: 2.1795 - acc: 0.9097 - val_loss: 4.6442 - val_acc: 0.5225\n",
      "Epoch 48/1024\n",
      "3000/3000 [==============================] - 162s - loss: 2.1495 - acc: 0.9153 - val_loss: 5.0073 - val_acc: 0.5178\n",
      "Epoch 49/1024\n",
      "3000/3000 [==============================] - 167s - loss: 2.1335 - acc: 0.9121 - val_loss: 4.7802 - val_acc: 0.5182\n",
      "Epoch 50/1024\n",
      "3000/3000 [==============================] - 177s - loss: 2.1140 - acc: 0.9104 - val_loss: 5.5999 - val_acc: 0.5098\n",
      "Epoch 51/1024\n",
      "3000/3000 [==============================] - 158s - loss: 2.0945 - acc: 0.9102 - val_loss: 4.7878 - val_acc: 0.5207\n",
      "Epoch 52/1024\n",
      "3000/3000 [==============================] - 154s - loss: 2.0660 - acc: 0.9135 - val_loss: 5.0930 - val_acc: 0.5165\n",
      "Epoch 53/1024\n",
      "3000/3000 [==============================] - 151s - loss: 2.0480 - acc: 0.9112 - val_loss: 5.0698 - val_acc: 0.5143\n",
      "Epoch 54/1024\n",
      "3000/3000 [==============================] - 162s - loss: 2.0321 - acc: 0.9141 - val_loss: 4.5996 - val_acc: 0.5235\n",
      "Epoch 55/1024\n",
      "3000/3000 [==============================] - 161s - loss: 2.0132 - acc: 0.9099 - val_loss: 5.4128 - val_acc: 0.5138\n",
      "Epoch 56/1024\n",
      "3000/3000 [==============================] - 181s - loss: 1.9901 - acc: 0.9138 - val_loss: 4.6622 - val_acc: 0.5125\n",
      "Epoch 57/1024\n",
      "3000/3000 [==============================] - 162s - loss: 1.9741 - acc: 0.9152 - val_loss: 3.9463 - val_acc: 0.5105\n",
      "Epoch 58/1024\n",
      "3000/3000 [==============================] - 157s - loss: 1.9519 - acc: 0.9158 - val_loss: 4.9291 - val_acc: 0.5130\n",
      "Epoch 59/1024\n",
      "3000/3000 [==============================] - 157s - loss: 1.9309 - acc: 0.9163 - val_loss: 4.8015 - val_acc: 0.5180\n",
      "Epoch 60/1024\n",
      "3000/3000 [==============================] - 158s - loss: 1.9142 - acc: 0.9146 - val_loss: 4.5026 - val_acc: 0.5213\n",
      "Epoch 61/1024\n",
      "3000/3000 [==============================] - 155s - loss: 1.9041 - acc: 0.9147 - val_loss: 4.9920 - val_acc: 0.5128\n",
      "Epoch 62/1024\n",
      "3000/3000 [==============================] - 158s - loss: 1.8832 - acc: 0.9143 - val_loss: 4.4715 - val_acc: 0.5152\n",
      "Epoch 63/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 153s - loss: 1.8621 - acc: 0.9196 - val_loss: 4.1444 - val_acc: 0.5187\n",
      "Epoch 64/1024\n",
      "3000/3000 [==============================] - 155s - loss: 1.8413 - acc: 0.9175 - val_loss: 4.8908 - val_acc: 0.5160\n",
      "Epoch 65/1024\n",
      "3000/3000 [==============================] - 161s - loss: 1.8264 - acc: 0.9173 - val_loss: 5.1524 - val_acc: 0.5120\n",
      "Epoch 66/1024\n",
      "3000/3000 [==============================] - 158s - loss: 1.8116 - acc: 0.9170 - val_loss: 4.7301 - val_acc: 0.5182\n",
      "Epoch 67/1024\n",
      "3000/3000 [==============================] - 161s - loss: 1.7880 - acc: 0.9210 - val_loss: 4.4357 - val_acc: 0.5115\n",
      "Epoch 68/1024\n",
      "3000/3000 [==============================] - 152s - loss: 1.7733 - acc: 0.9199 - val_loss: 5.3662 - val_acc: 0.5085\n",
      "Epoch 69/1024\n",
      "3000/3000 [==============================] - 152s - loss: 1.7652 - acc: 0.9146 - val_loss: 4.8450 - val_acc: 0.5142\n",
      "Epoch 70/1024\n",
      "3000/3000 [==============================] - 157s - loss: 1.7545 - acc: 0.9142 - val_loss: 4.1976 - val_acc: 0.5233\n",
      "Epoch 71/1024\n",
      "3000/3000 [==============================] - 152s - loss: 1.7293 - acc: 0.9129 - val_loss: 5.3291 - val_acc: 0.5128\n",
      "Epoch 72/1024\n",
      "3000/3000 [==============================] - 148s - loss: 1.7141 - acc: 0.9174 - val_loss: 4.8418 - val_acc: 0.5142\n",
      "Epoch 73/1024\n",
      "3000/3000 [==============================] - 166s - loss: 1.7046 - acc: 0.9167 - val_loss: 4.5309 - val_acc: 0.5195\n",
      "Epoch 74/1024\n",
      "3000/3000 [==============================] - 164s - loss: 1.6832 - acc: 0.9198 - val_loss: 4.7500 - val_acc: 0.5185\n",
      "Epoch 75/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.6700 - acc: 0.9210 - val_loss: 4.5467 - val_acc: 0.5140\n",
      "Epoch 76/1024\n",
      "3000/3000 [==============================] - 151s - loss: 1.6514 - acc: 0.9212 - val_loss: 4.2288 - val_acc: 0.5180\n",
      "Epoch 77/1024\n",
      "3000/3000 [==============================] - 150s - loss: 1.6410 - acc: 0.9207 - val_loss: 4.8043 - val_acc: 0.5128\n",
      "Epoch 78/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.6248 - acc: 0.9203 - val_loss: 4.6520 - val_acc: 0.5177\n",
      "Epoch 79/1024\n",
      "3000/3000 [==============================] - 148s - loss: 1.6104 - acc: 0.9193 - val_loss: 4.4817 - val_acc: 0.5240\n",
      "Epoch 80/1024\n",
      "3000/3000 [==============================] - 155s - loss: 1.5961 - acc: 0.9197 - val_loss: 4.4537 - val_acc: 0.5182\n",
      "Epoch 81/1024\n",
      "3000/3000 [==============================] - 150s - loss: 1.5786 - acc: 0.9214 - val_loss: 5.1376 - val_acc: 0.5085\n",
      "Epoch 82/1024\n",
      "3000/3000 [==============================] - 153s - loss: 1.5666 - acc: 0.9213 - val_loss: 4.4204 - val_acc: 0.5180\n",
      "Epoch 83/1024\n",
      "3000/3000 [==============================] - 154s - loss: 1.5566 - acc: 0.9204 - val_loss: 4.5705 - val_acc: 0.5165\n",
      "Epoch 84/1024\n",
      "3000/3000 [==============================] - 155s - loss: 1.5394 - acc: 0.9250 - val_loss: 4.1764 - val_acc: 0.5182\n",
      "Epoch 85/1024\n",
      "3000/3000 [==============================] - 151s - loss: 1.5229 - acc: 0.9263 - val_loss: 3.9458 - val_acc: 0.5210\n",
      "Epoch 86/1024\n",
      "3000/3000 [==============================] - 154s - loss: 1.5192 - acc: 0.9223 - val_loss: 4.2058 - val_acc: 0.5222\n",
      "Epoch 87/1024\n",
      "3000/3000 [==============================] - 166s - loss: 1.4982 - acc: 0.9237 - val_loss: 4.7555 - val_acc: 0.5170\n",
      "Epoch 88/1024\n",
      "3000/3000 [==============================] - 151s - loss: 1.4895 - acc: 0.9243 - val_loss: 4.5892 - val_acc: 0.5115\n",
      "Epoch 89/1024\n",
      "3000/3000 [==============================] - 153s - loss: 1.4706 - acc: 0.9219 - val_loss: 4.7627 - val_acc: 0.5135\n",
      "Epoch 90/1024\n",
      "3000/3000 [==============================] - 168s - loss: 1.4573 - acc: 0.9272 - val_loss: 4.8095 - val_acc: 0.5162\n",
      "Epoch 91/1024\n",
      "3000/3000 [==============================] - 158s - loss: 1.4528 - acc: 0.9221 - val_loss: 4.6372 - val_acc: 0.5118\n",
      "Epoch 92/1024\n",
      "3000/3000 [==============================] - 166s - loss: 1.4386 - acc: 0.9240 - val_loss: 4.1719 - val_acc: 0.5200\n",
      "Epoch 93/1024\n",
      "3000/3000 [==============================] - 165s - loss: 1.4208 - acc: 0.9256 - val_loss: 5.1826 - val_acc: 0.5085\n",
      "Epoch 94/1024\n",
      "3000/3000 [==============================] - 145s - loss: 1.4101 - acc: 0.9276 - val_loss: 4.5284 - val_acc: 0.5135\n",
      "Epoch 95/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.4024 - acc: 0.9250 - val_loss: 4.7423 - val_acc: 0.5170\n",
      "Epoch 96/1024\n",
      "3000/3000 [==============================] - 155s - loss: 1.3851 - acc: 0.9286 - val_loss: 4.6540 - val_acc: 0.5155\n",
      "Epoch 97/1024\n",
      "3000/3000 [==============================] - 152s - loss: 1.3721 - acc: 0.9280 - val_loss: 5.0765 - val_acc: 0.5098\n",
      "Epoch 98/1024\n",
      "3000/3000 [==============================] - 156s - loss: 1.3714 - acc: 0.9246 - val_loss: 4.5837 - val_acc: 0.5185\n",
      "Epoch 99/1024\n",
      "3000/3000 [==============================] - 155s - loss: 1.3498 - acc: 0.9269 - val_loss: 4.5933 - val_acc: 0.5203\n",
      "Epoch 100/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.3344 - acc: 0.9304 - val_loss: 5.1803 - val_acc: 0.5098\n",
      "Epoch 101/1024\n",
      "3000/3000 [==============================] - 156s - loss: 1.3277 - acc: 0.9252 - val_loss: 5.0046 - val_acc: 0.5125\n",
      "Epoch 102/1024\n",
      "3000/3000 [==============================] - 164s - loss: 1.3236 - acc: 0.9285 - val_loss: 5.1469 - val_acc: 0.5088\n",
      "Epoch 103/1024\n",
      "3000/3000 [==============================] - 165s - loss: 1.3100 - acc: 0.9248 - val_loss: 4.3510 - val_acc: 0.5143\n",
      "Epoch 104/1024\n",
      "3000/3000 [==============================] - 148s - loss: 1.2933 - acc: 0.9328 - val_loss: 3.9603 - val_acc: 0.5130\n",
      "Epoch 105/1024\n",
      "3000/3000 [==============================] - 153s - loss: 1.2825 - acc: 0.9288 - val_loss: 4.1511 - val_acc: 0.5160\n",
      "Epoch 106/1024\n",
      "3000/3000 [==============================] - 150s - loss: 1.2764 - acc: 0.9281 - val_loss: 4.6395 - val_acc: 0.5125\n",
      "Epoch 107/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.2673 - acc: 0.9288 - val_loss: 4.6337 - val_acc: 0.5127\n",
      "Epoch 108/1024\n",
      "3000/3000 [==============================] - 158s - loss: 1.2505 - acc: 0.9295 - val_loss: 5.1404 - val_acc: 0.5058\n",
      "Epoch 109/1024\n",
      "3000/3000 [==============================] - 151s - loss: 1.2495 - acc: 0.9262 - val_loss: 4.9592 - val_acc: 0.5088\n",
      "Epoch 110/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.2309 - acc: 0.9310 - val_loss: 4.5267 - val_acc: 0.5175\n",
      "Epoch 111/1024\n",
      "3000/3000 [==============================] - 154s - loss: 1.2251 - acc: 0.9293 - val_loss: 4.6647 - val_acc: 0.5110\n",
      "Epoch 112/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.2108 - acc: 0.9304 - val_loss: 4.8449 - val_acc: 0.5152\n",
      "Epoch 113/1024\n",
      "3000/3000 [==============================] - 156s - loss: 1.2093 - acc: 0.9288 - val_loss: 4.3131 - val_acc: 0.5180\n",
      "Epoch 114/1024\n",
      "3000/3000 [==============================] - 150s - loss: 1.1967 - acc: 0.9291 - val_loss: 4.6112 - val_acc: 0.5155\n",
      "Epoch 115/1024\n",
      "3000/3000 [==============================] - 150s - loss: 1.1837 - acc: 0.9313 - val_loss: 5.2827 - val_acc: 0.5037\n",
      "Epoch 116/1024\n",
      "3000/3000 [==============================] - 156s - loss: 1.1753 - acc: 0.9301 - val_loss: 4.7570 - val_acc: 0.5125\n",
      "Epoch 117/1024\n",
      "3000/3000 [==============================] - 153s - loss: 1.1688 - acc: 0.9298 - val_loss: 4.6071 - val_acc: 0.5147\n",
      "Epoch 118/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.1573 - acc: 0.9310 - val_loss: 4.1727 - val_acc: 0.5188\n",
      "Epoch 119/1024\n",
      "3000/3000 [==============================] - 150s - loss: 1.1481 - acc: 0.9317 - val_loss: 4.5669 - val_acc: 0.5173\n",
      "Epoch 120/1024\n",
      "3000/3000 [==============================] - 165s - loss: 1.1383 - acc: 0.9317 - val_loss: 4.6897 - val_acc: 0.5120\n",
      "Epoch 121/1024\n",
      "3000/3000 [==============================] - 152s - loss: 1.1315 - acc: 0.9327 - val_loss: 4.2448 - val_acc: 0.5160\n",
      "Epoch 122/1024\n",
      "3000/3000 [==============================] - 159s - loss: 1.1187 - acc: 0.9337 - val_loss: 4.2123 - val_acc: 0.5168\n",
      "Epoch 123/1024\n",
      "3000/3000 [==============================] - 150s - loss: 1.1132 - acc: 0.9318 - val_loss: 4.6343 - val_acc: 0.5167\n",
      "Epoch 124/1024\n",
      "3000/3000 [==============================] - 154s - loss: 1.1069 - acc: 0.9322 - val_loss: 4.1221 - val_acc: 0.5185\n",
      "Epoch 125/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 153s - loss: 1.0949 - acc: 0.9334 - val_loss: 4.2798 - val_acc: 0.5097\n",
      "Epoch 126/1024\n",
      "3000/3000 [==============================] - 161s - loss: 1.0903 - acc: 0.9328 - val_loss: 4.3476 - val_acc: 0.5158\n",
      "Epoch 127/1024\n",
      "3000/3000 [==============================] - 155s - loss: 1.0846 - acc: 0.9329 - val_loss: 4.2484 - val_acc: 0.5185\n",
      "Epoch 128/1024\n",
      "3000/3000 [==============================] - 154s - loss: 1.0678 - acc: 0.9334 - val_loss: 5.1565 - val_acc: 0.5105\n",
      "Epoch 129/1024\n",
      "3000/3000 [==============================] - 154s - loss: 1.0631 - acc: 0.9307 - val_loss: 4.8286 - val_acc: 0.5142\n",
      "Epoch 130/1024\n",
      "3000/3000 [==============================] - 163s - loss: 1.0557 - acc: 0.9325 - val_loss: 3.6556 - val_acc: 0.5217\n",
      "Epoch 131/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.0435 - acc: 0.9372 - val_loss: 4.4967 - val_acc: 0.5092\n",
      "Epoch 132/1024\n",
      "3000/3000 [==============================] - 150s - loss: 1.0420 - acc: 0.9321 - val_loss: 4.7633 - val_acc: 0.5103\n",
      "Epoch 133/1024\n",
      "3000/3000 [==============================] - 157s - loss: 1.0308 - acc: 0.9338 - val_loss: 4.0878 - val_acc: 0.5150\n",
      "Epoch 134/1024\n",
      "3000/3000 [==============================] - 146s - loss: 1.0237 - acc: 0.9323 - val_loss: 4.3491 - val_acc: 0.5168\n",
      "Epoch 135/1024\n",
      "3000/3000 [==============================] - 145s - loss: 1.0145 - acc: 0.9338 - val_loss: 4.1305 - val_acc: 0.5107\n",
      "Epoch 136/1024\n",
      "3000/3000 [==============================] - 153s - loss: 1.0034 - acc: 0.9362 - val_loss: 4.5493 - val_acc: 0.5175\n",
      "Epoch 137/1024\n",
      "3000/3000 [==============================] - 149s - loss: 1.0025 - acc: 0.9339 - val_loss: 5.0547 - val_acc: 0.5083\n",
      "Epoch 138/1024\n",
      "3000/3000 [==============================] - 169s - loss: 0.9944 - acc: 0.9351 - val_loss: 4.6671 - val_acc: 0.5092\n",
      "Epoch 139/1024\n",
      "3000/3000 [==============================] - 162s - loss: 0.9852 - acc: 0.9359 - val_loss: 4.5409 - val_acc: 0.5142\n",
      "Epoch 140/1024\n",
      "3000/3000 [==============================] - 160s - loss: 0.9746 - acc: 0.9389 - val_loss: 5.1334 - val_acc: 0.5055\n",
      "Epoch 141/1024\n",
      "3000/3000 [==============================] - 150s - loss: 0.9779 - acc: 0.9357 - val_loss: 4.3743 - val_acc: 0.5123\n",
      "Epoch 142/1024\n",
      "3000/3000 [==============================] - 157s - loss: 0.9618 - acc: 0.9359 - val_loss: 5.0479 - val_acc: 0.5072\n",
      "Epoch 143/1024\n",
      "3000/3000 [==============================] - 163s - loss: 0.9572 - acc: 0.9343 - val_loss: 4.7297 - val_acc: 0.5082\n",
      "Epoch 144/1024\n",
      "3000/3000 [==============================] - 168s - loss: 0.9524 - acc: 0.9359 - val_loss: 4.6894 - val_acc: 0.5092\n",
      "Epoch 145/1024\n",
      "3000/3000 [==============================] - 167s - loss: 0.9477 - acc: 0.9375 - val_loss: 4.5253 - val_acc: 0.5107\n",
      "Epoch 146/1024\n",
      "3000/3000 [==============================] - 156s - loss: 0.9402 - acc: 0.9365 - val_loss: 4.7142 - val_acc: 0.5108\n",
      "Epoch 147/1024\n",
      "3000/3000 [==============================] - 161s - loss: 0.9348 - acc: 0.9352 - val_loss: 4.5318 - val_acc: 0.5095\n",
      "Epoch 148/1024\n",
      "3000/3000 [==============================] - 163s - loss: 0.9291 - acc: 0.9366 - val_loss: 4.8033 - val_acc: 0.5070\n",
      "Epoch 149/1024\n",
      "3000/3000 [==============================] - 155s - loss: 0.9182 - acc: 0.9350 - val_loss: 4.6066 - val_acc: 0.5150\n",
      "Epoch 150/1024\n",
      "3000/3000 [==============================] - 154s - loss: 0.9164 - acc: 0.9362 - val_loss: 4.9370 - val_acc: 0.5100\n",
      "Epoch 151/1024\n",
      "3000/3000 [==============================] - 153s - loss: 0.9063 - acc: 0.9377 - val_loss: 5.2906 - val_acc: 0.5075\n",
      "Epoch 152/1024\n",
      "3000/3000 [==============================] - 169s - loss: 0.8958 - acc: 0.9402 - val_loss: 4.8002 - val_acc: 0.5092\n",
      "Epoch 153/1024\n",
      "3000/3000 [==============================] - 159s - loss: 0.8986 - acc: 0.9344 - val_loss: 5.0438 - val_acc: 0.5098\n",
      "Epoch 154/1024\n",
      "3000/3000 [==============================] - 166s - loss: 0.8825 - acc: 0.9397 - val_loss: 4.3639 - val_acc: 0.5135\n",
      "Epoch 155/1024\n",
      "3000/3000 [==============================] - 154s - loss: 0.8893 - acc: 0.9364 - val_loss: 4.5204 - val_acc: 0.5112\n",
      "Epoch 156/1024\n",
      "3000/3000 [==============================] - 166s - loss: 0.8801 - acc: 0.9350 - val_loss: 4.7483 - val_acc: 0.5090\n",
      "Epoch 157/1024\n",
      "3000/3000 [==============================] - 160s - loss: 0.8749 - acc: 0.9360 - val_loss: 4.7939 - val_acc: 0.5110\n",
      "Epoch 158/1024\n",
      "3000/3000 [==============================] - 156s - loss: 0.8697 - acc: 0.9377 - val_loss: 4.8454 - val_acc: 0.5113\n",
      "Epoch 159/1024\n",
      "3000/3000 [==============================] - 151s - loss: 0.8549 - acc: 0.9398 - val_loss: 3.8302 - val_acc: 0.5120\n",
      "Epoch 160/1024\n",
      "3000/3000 [==============================] - 151s - loss: 0.8477 - acc: 0.9408 - val_loss: 4.3357 - val_acc: 0.5087\n",
      "Epoch 161/1024\n",
      "3000/3000 [==============================] - 153s - loss: 0.8522 - acc: 0.9385 - val_loss: 4.9666 - val_acc: 0.5070\n",
      "Epoch 162/1024\n",
      "3000/3000 [==============================] - 165s - loss: 0.8473 - acc: 0.9358 - val_loss: 3.6774 - val_acc: 0.5120\n",
      "Epoch 163/1024\n",
      "3000/3000 [==============================] - 162s - loss: 0.8332 - acc: 0.9419 - val_loss: 4.6652 - val_acc: 0.5065\n",
      "Epoch 164/1024\n",
      "3000/3000 [==============================] - 161s - loss: 0.8345 - acc: 0.9416 - val_loss: 3.7627 - val_acc: 0.5160\n",
      "Epoch 165/1024\n",
      "3000/3000 [==============================] - 163s - loss: 0.8237 - acc: 0.9430 - val_loss: 4.7141 - val_acc: 0.5080\n",
      "Epoch 166/1024\n",
      "3000/3000 [==============================] - 152s - loss: 0.8139 - acc: 0.9433 - val_loss: 4.5100 - val_acc: 0.5145\n",
      "Epoch 167/1024\n",
      "3000/3000 [==============================] - 155s - loss: 0.8164 - acc: 0.9426 - val_loss: 4.8751 - val_acc: 0.5103\n",
      "Epoch 168/1024\n",
      "3000/3000 [==============================] - 160s - loss: 0.8054 - acc: 0.9457 - val_loss: 5.1499 - val_acc: 0.5068\n",
      "Epoch 169/1024\n",
      "3000/3000 [==============================] - 158s - loss: 0.8076 - acc: 0.9429 - val_loss: 5.0529 - val_acc: 0.5082\n",
      "Epoch 170/1024\n",
      "3000/3000 [==============================] - 154s - loss: 0.8016 - acc: 0.9398 - val_loss: 4.3185 - val_acc: 0.5147\n",
      "Epoch 171/1024\n",
      "3000/3000 [==============================] - 156s - loss: 0.7891 - acc: 0.9440 - val_loss: 4.4676 - val_acc: 0.5057\n",
      "Epoch 172/1024\n",
      "3000/3000 [==============================] - 159s - loss: 0.7911 - acc: 0.9409 - val_loss: 4.5109 - val_acc: 0.5098\n",
      "Epoch 173/1024\n",
      "3000/3000 [==============================] - 168s - loss: 0.7795 - acc: 0.9418 - val_loss: 5.3158 - val_acc: 0.5092\n",
      "Epoch 174/1024\n",
      "3000/3000 [==============================] - 172s - loss: 0.7839 - acc: 0.9403 - val_loss: 4.9552 - val_acc: 0.5082\n",
      "Epoch 175/1024\n",
      "3000/3000 [==============================] - 164s - loss: 0.7732 - acc: 0.9421 - val_loss: 4.4887 - val_acc: 0.5117\n",
      "Epoch 176/1024\n",
      "3000/3000 [==============================] - 154s - loss: 0.7693 - acc: 0.9419 - val_loss: 4.7079 - val_acc: 0.5090\n",
      "Epoch 177/1024\n",
      "3000/3000 [==============================] - 154s - loss: 0.7654 - acc: 0.9460 - val_loss: 4.3749 - val_acc: 0.5130\n",
      "Epoch 178/1024\n",
      "3000/3000 [==============================] - 164s - loss: 0.7646 - acc: 0.9403 - val_loss: 5.3792 - val_acc: 0.5068\n",
      "Epoch 179/1024\n",
      "3000/3000 [==============================] - 184s - loss: 0.7552 - acc: 0.9432 - val_loss: 4.4243 - val_acc: 0.5150\n",
      "Epoch 180/1024\n",
      "3000/3000 [==============================] - 165s - loss: 0.7531 - acc: 0.9394 - val_loss: 3.8205 - val_acc: 0.5100\n",
      "Epoch 181/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.7466 - acc: 0.9422 - val_loss: 4.1454 - val_acc: 0.5132\n",
      "Epoch 182/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.7452 - acc: 0.9442 - val_loss: 4.9477 - val_acc: 0.5102\n",
      "Epoch 183/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.7388 - acc: 0.9433 - val_loss: 4.6763 - val_acc: 0.5090\n",
      "Epoch 184/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.7337 - acc: 0.9425 - val_loss: 4.7187 - val_acc: 0.5140\n",
      "Epoch 185/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.7276 - acc: 0.9428 - val_loss: 5.1016 - val_acc: 0.5060\n",
      "Epoch 186/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.7266 - acc: 0.9452 - val_loss: 4.9392 - val_acc: 0.5053\n",
      "Epoch 187/1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 143s - loss: 0.7271 - acc: 0.9426 - val_loss: 4.7994 - val_acc: 0.5065\n",
      "Epoch 188/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.7205 - acc: 0.9425 - val_loss: 4.5834 - val_acc: 0.5078\n",
      "Epoch 189/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.7133 - acc: 0.9427 - val_loss: 4.1290 - val_acc: 0.5110\n",
      "Epoch 190/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.7172 - acc: 0.9408 - val_loss: 4.9997 - val_acc: 0.5102\n",
      "Epoch 191/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.7005 - acc: 0.9458 - val_loss: 4.8044 - val_acc: 0.5068\n",
      "Epoch 192/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.7005 - acc: 0.9439 - val_loss: 4.6824 - val_acc: 0.5072\n",
      "Epoch 193/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.7008 - acc: 0.9449 - val_loss: 4.8990 - val_acc: 0.5052\n",
      "Epoch 194/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6939 - acc: 0.9451 - val_loss: 4.6404 - val_acc: 0.5093\n",
      "Epoch 195/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6964 - acc: 0.9435 - val_loss: 4.3496 - val_acc: 0.5130\n",
      "Epoch 196/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6805 - acc: 0.9474 - val_loss: 4.4972 - val_acc: 0.5113\n",
      "Epoch 197/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6822 - acc: 0.9464 - val_loss: 4.8074 - val_acc: 0.5108\n",
      "Epoch 198/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.6768 - acc: 0.9465 - val_loss: 4.4657 - val_acc: 0.5052\n",
      "Epoch 199/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6748 - acc: 0.9453 - val_loss: 5.1972 - val_acc: 0.5052\n",
      "Epoch 200/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6725 - acc: 0.9464 - val_loss: 4.4758 - val_acc: 0.5095\n",
      "Epoch 201/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6650 - acc: 0.9437 - val_loss: 4.8525 - val_acc: 0.5103\n",
      "Epoch 202/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6628 - acc: 0.9466 - val_loss: 4.2473 - val_acc: 0.5142\n",
      "Epoch 203/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.6589 - acc: 0.9453 - val_loss: 4.7321 - val_acc: 0.5103\n",
      "Epoch 204/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.6544 - acc: 0.9467 - val_loss: 4.6274 - val_acc: 0.5058\n",
      "Epoch 205/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6548 - acc: 0.9449 - val_loss: 4.9146 - val_acc: 0.5062\n",
      "Epoch 206/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.6473 - acc: 0.9467 - val_loss: 4.4824 - val_acc: 0.5093\n",
      "Epoch 207/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.6410 - acc: 0.9497 - val_loss: 5.1995 - val_acc: 0.5090\n",
      "Epoch 208/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6404 - acc: 0.9453 - val_loss: 4.7189 - val_acc: 0.5075\n",
      "Epoch 209/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.6381 - acc: 0.9469 - val_loss: 4.5040 - val_acc: 0.5088\n",
      "Epoch 210/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6304 - acc: 0.9496 - val_loss: 4.6338 - val_acc: 0.5070\n",
      "Epoch 211/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6364 - acc: 0.9465 - val_loss: 4.0782 - val_acc: 0.5118\n",
      "Epoch 212/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6264 - acc: 0.9483 - val_loss: 4.8647 - val_acc: 0.5140\n",
      "Epoch 213/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6269 - acc: 0.9473 - val_loss: 4.7391 - val_acc: 0.5050\n",
      "Epoch 214/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6249 - acc: 0.9468 - val_loss: 5.0398 - val_acc: 0.5045\n",
      "Epoch 215/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6222 - acc: 0.9471 - val_loss: 4.8305 - val_acc: 0.5028\n",
      "Epoch 216/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6105 - acc: 0.9518 - val_loss: 5.2077 - val_acc: 0.5055\n",
      "Epoch 217/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6100 - acc: 0.9491 - val_loss: 4.5849 - val_acc: 0.5150\n",
      "Epoch 218/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.6060 - acc: 0.9497 - val_loss: 5.4753 - val_acc: 0.5078\n",
      "Epoch 219/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.6036 - acc: 0.9479 - val_loss: 4.3448 - val_acc: 0.5083\n",
      "Epoch 220/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.6077 - acc: 0.9452 - val_loss: 4.7582 - val_acc: 0.5060\n",
      "Epoch 221/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5988 - acc: 0.9496 - val_loss: 4.9146 - val_acc: 0.5058\n",
      "Epoch 222/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5922 - acc: 0.9517 - val_loss: 4.8543 - val_acc: 0.5050\n",
      "Epoch 223/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.5968 - acc: 0.9490 - val_loss: 4.5334 - val_acc: 0.5125\n",
      "Epoch 224/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5929 - acc: 0.9481 - val_loss: 4.2494 - val_acc: 0.5045\n",
      "Epoch 225/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5856 - acc: 0.9518 - val_loss: 4.9710 - val_acc: 0.5105\n",
      "Epoch 226/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5912 - acc: 0.9497 - val_loss: 5.2269 - val_acc: 0.5065\n",
      "Epoch 227/1024\n",
      "3000/3000 [==============================] - 144s - loss: 0.5840 - acc: 0.9506 - val_loss: 5.0768 - val_acc: 0.5050\n",
      "Epoch 228/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5837 - acc: 0.9483 - val_loss: 4.3084 - val_acc: 0.5070\n",
      "Epoch 229/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5689 - acc: 0.9534 - val_loss: 4.8560 - val_acc: 0.5035\n",
      "Epoch 230/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5707 - acc: 0.9531 - val_loss: 5.1557 - val_acc: 0.5062\n",
      "Epoch 231/1024\n",
      "3000/3000 [==============================] - 143s - loss: 0.5723 - acc: 0.9498 - val_loss: 3.9560 - val_acc: 0.5168\n",
      "Epoch 00230: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto')\n",
    "# history = LossHistory()\n",
    "fitting=model.fit(train_x, train_y, batch_size=64, epochs=1024,\n",
    "          validation_split=0.25, verbose=1, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c5fa33f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = fitting.history['loss']\n",
    "val_loss = fitting.history['val_loss']\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend (Overfitting)')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/Users/sunchenxi/Desktop/lab/code/planet/my_model_weather.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.56148054e-08,   9.99999881e-01,   1.08895918e-07,\n",
       "          2.36200295e-12]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(resized_images[1040])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[1040]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
